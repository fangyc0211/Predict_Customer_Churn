{"cells":[{"metadata":{"_uuid":"6e768cae-c343-4530-ab84-77c19823b4d1","_cell_guid":"18948037-7431-40f4-befd-ab52d5aff6f9","trusted":true},"cell_type":"markdown","source":"# Telecom Customer Churn Prediction"},{"metadata":{"_uuid":"3f9a9451-26c6-4707-a0b5-7d645af3ae0d","_cell_guid":"8f5cf825-1806-4977-a9dc-5d022611407c","trusted":true},"cell_type":"markdown","source":"**Introduction**\n\nCustomer Churn/Attrition is the loss of clients, which is defined as the propensity of a customer to stop doing business with an organization in a given time period.\n\nTelecom industires (Telephone/Internet service providers) often use customer churn analysis and customer churn rate as one of their key business metrics, because the cost of retaining an existing customer is far less than acquring a new one. Therefore, it's important to know churning customers beforehand. \n\nPredictive analytics use churn prediction models that predict customer churn by assessing their propensity of risk to churn. Since these models generate a small prioritized list of potential defectors, they are effective at focusing customer retention marketing programs on the subset of the customer base who are most vulnerable to churn."},{"metadata":{"_uuid":"0313a819-7cd2-4bae-a95c-9aabc5c65dcc","_cell_guid":"4ad20fa9-ff80-495a-a47f-d6b98afed619","trusted":true},"cell_type":"markdown","source":"**About the Analysis:**\n* This analysis focuses on the behaviour of telecom customers through EDA, and later use predictive analytics to determine the customers who are most likely to churn.\n\n\n\n**About the data:**\n* Customers who left in last month - the column is called Churn\n* Services that each customer has signed up for - phone, multiple lines, internet, online securitiy, online backup, device protection, tech support, and streaming TV and movies\n* Customer account information - how long they've been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n* Demographic info - gender, age range, and if they have partners and dependents"},{"metadata":{"_uuid":"1a7e4ca7-7564-4015-86ee-7c3f75641da1","_cell_guid":"8511fc01-efc2-43a8-87e8-5cc48885b476","trusted":true},"cell_type":"markdown","source":"- <a href='#1'>1. Data overview</a>\n- <a href='#2'>2. Data Manipulation</a>\n    - <a href='#2.1'>2.1. Convert Data Types</a>\n    - <a href='#2.2'>2.2. Missing Value</a>\n- <a href='#3'>3. Exploratory Data Analysis</a>\n    - <a href='#3.1'>3.1. Target Variable - Churn Distribution</a>\n    - <a href='#3.2'>3.2. Demographic Analysis</a>\n        - <a href='#3.2.1'>3.2.1 Gender\n        - <a href='#3.2.2'>3.2.2 Senior Citizen\n        - <a href='#3.2.3'>3.2.3 Partner and Dependent Status\n    - <a href='#3.3'>3.3. Customer Account Information</a>\n        - <a href='#3.3.1'>3.3.1 Tenure\n        - <a href='#3.3.2'>3.3.2 Contract Type\n    - <a href='#3.4'>3.4. Services</a>\n    - <a href='#3.5'>3.5. Monthly and Total Charges</a>       \n- <a href='#4'>4. Model Building</a>\n    - <a href='#4.1'>4.1. Data Preprocessing</a>\n         - <a href='#4.1.1'>4.1.1 Converting Categorical Variables to Dummy Variables\n         - <a href='#4.1.2'>4.1.2 Scaling All Variables\n         - <a href='#4.1.3'>4.1.3 Correlation Analysis\n    - <a href='#4.2'>4.2. Baseline Model - Logistic Regression</a>\n    - <a href='#4.3'>4.3. Random Forest</a>\n    - <a href='#4.4'>4.4. XGBoost</a>"},{"metadata":{"_uuid":"258f335c-11ab-4026-b9b9-7de322fa2a17","_cell_guid":"dcc60ed2-8897-4204-8cd4-ec4bfbe15d7d","trusted":true},"cell_type":"code","source":"#Importing libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\nimport seaborn as sns # visualization\nsns.set(style = 'white')\nimport matplotlib.ticker as mtick # For specifying the axes tick format \nimport matplotlib.pyplot as plt #visualization\n\nimport plotly.offline as py#visualization\npy.init_notebook_mode(connected=True)#visualization\nimport plotly.graph_objs as go#visualization\nimport plotly.tools as tls#visualization\nimport plotly.figure_factory as ff#visualization\n\n\nfrom sklearn.model_selection import train_test_split #splitting training and testing set\nfrom sklearn.linear_model import LogisticRegression #Logistic Regression\nfrom sklearn.ensemble import RandomForestClassifier #Random Forest\nfrom xgboost import XGBClassifier #XGBoost\n\nfrom sklearn.metrics import accuracy_score, classification_report #Performance Measure\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb1aa35e-8f43-4897-ae61-b443eacd1c12","_cell_guid":"819a2eaf-5839-4348-8c82-430008cdcd87","trusted":true},"cell_type":"markdown","source":"# 1. Data Overview"},{"metadata":{"_uuid":"d787ebed-796d-4549-bcf5-fa6432318400","_cell_guid":"295970e8-b84e-446a-869f-98331b242ba3","trusted":true},"cell_type":"code","source":"#Read csv and display first few rows\ntelecom = pd.read_csv('/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ntelecom.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02a4ae91-3bdd-48fe-b759-fd789051b6e9","_cell_guid":"fb981188-7460-4e89-a953-7a0dcb9f6ebc","trusted":true,"scrolled":true},"cell_type":"code","source":"#Data overview\nprint (\"Rows     : \" ,telecom.shape[0])\nprint (\"Columns  : \" ,telecom.shape[1])\nprint (\"\\nFeatures : \\n\" ,telecom.columns.tolist())\nprint (\"\\nData types : \\n\" ,telecom.dtypes)\nprint (\"\\nUnique values :  \\n\",telecom.nunique())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10287fc3-5a37-4c70-beec-281a4400e144","_cell_guid":"79e27709-534c-4bad-b82e-6a467eb49265","trusted":true},"cell_type":"markdown","source":"# 2. Data Manipulation"},{"metadata":{"_uuid":"76f46725-67a7-4fff-b2bc-8a751b520884","_cell_guid":"e96a538c-a373-4ffb-b362-db7cdbf600c9","trusted":true},"cell_type":"markdown","source":"# 2.1 Convert Data Types"},{"metadata":{"_uuid":"33681844-9103-4df0-bf08-62aaa5a29fed","_cell_guid":"b1e7a952-4fac-45b9-885b-88b5c45756c9","trusted":true},"cell_type":"markdown","source":"We noticed the type of 'Total Charges' is object, we want to convert the type into a numerical data type."},{"metadata":{"_uuid":"74360321-fda1-4759-84bc-412e392bbd1d","_cell_guid":"d2580bf2-a963-4aac-aa76-03d6717fcc4f","trusted":true},"cell_type":"code","source":"# Converting Total Charges to a numerical data type, using pandas.to_numeric\n# if errors='coerce',then invalid parsing will be set as NaN.\ntelecom.TotalCharges = pd.to_numeric(telecom.TotalCharges,errors='coerce')\nprint (\"\\nMissing values :  \\n\",telecom.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14d5b128-c22a-4fbc-b933-c20d7b9fdb5f","_cell_guid":"2c34b712-50ff-429c-b28b-c16564e1a12b","trusted":true},"cell_type":"markdown","source":"# 2.2 Missing Value"},{"metadata":{"_uuid":"cd6950e3-186e-41cb-9bd4-ad1c1aede59f","_cell_guid":"5d1cc0f0-fc2e-4aa6-913e-6fe0d992901d","trusted":true},"cell_type":"markdown","source":"After looking at the above output, we can say that there are 11 missing values for Total Charges. \n\nSteps to handle missing values:\n1. Calculate the % of missing values.\n2. If the % is very small, the easiest way is to delete the records, as there's a minimal impact to the dataset.\n3. If the % is small, impute missing values with avg/median or try other imputation methods (eg. KNN).It can only work with numeric data. \n4. If the % is signicant, general imputation method may not work, as it may introduce too much bias into the dataset. The variable is not accurate. Delete/replace the variable.\n5. Try different algorithms. Some algorithms can factor in the missing values and learn the best imputation values for the missing data based on the training loss reduction (ie. XGBoost). Some others have the option to just ignore them (ie. LightGBM â€” use_missing=false)\n\n\nIn our case, we only found 11 missing values, which is around 0.1% out of 7043 rows, let us remove these 11 rows from our dataset"},{"metadata":{"_uuid":"182c8a80-1a94-47c4-b3ae-c6753d245a6a","_cell_guid":"1cc9694c-0ec4-4a74-99ec-e20c75022a46","trusted":true},"cell_type":"code","source":"#Removing 11 missing values,\n#When inplace = True , the data is modified in place, which means it will return nothing and the dataframe is now updated. \ntelecom.dropna(inplace = True)\n\n#double-check if missing value has been removed.\nprint (\"Rows     : \" ,telecom.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7fc70cdf-f5ab-47b5-b3db-df384ba83957","_cell_guid":"b8f2376d-175f-4add-83dc-ea791e5b9fef","trusted":true},"cell_type":"markdown","source":"# 3. Exploratory Data Analysis\n\nLet us first start with exploring our data set, to better understand the patterns in the data and potentially form some hypothesis. First we will look at Correlation analysis, and then observe the distribution of individual variables and then slice and dice our data for any interesting trends."},{"metadata":{"_uuid":"12429d77-ca06-4b6a-92ea-f918b1bf1142","_cell_guid":"54356e00-63bd-44a3-81ff-df4e0cc0e8ad","trusted":true},"cell_type":"markdown","source":"# 3.1 Target Variable - Churn Distribution"},{"metadata":{"_uuid":"275d24a0-4422-4e85-b856-35f659a2b402","_cell_guid":"c07052fd-2352-4654-af72-2eded641294c","trusted":true},"cell_type":"markdown","source":"We are trying to predict if the client left the company in the previous month. Therefore we have a binary classification problem with a slightly unbalanced target:\n\n* Churn: No - 73.4%\n* Churn: Yes - 26.6%"},{"metadata":{"_uuid":"1836993c-d0d4-4f9f-aeef-b2148dccd471","_cell_guid":"901b5c58-ee80-45b3-bed3-8d95542b65cc","trusted":true},"cell_type":"markdown","source":"Note: How to handle imbalanced data?\n\n- Oversampling \n- Undersampling \n- Try different algorithms by adjusting the weights (Hyperparameters tuning)"},{"metadata":{"_uuid":"89b999e6-7046-401a-897e-a11d3e8e4d03","_cell_guid":"842a630b-aefa-4bbd-8f4f-07bad74b733e","trusted":true},"cell_type":"code","source":"ax = (telecom['Churn'].value_counts()*100.0 /len(telecom))\\\n.plot.pie(autopct='%.1f%%',figsize =(5,5), fontsize = 12 )                                                                           \nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.set_title('Churn Distribution', fontsize = 12)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ac6c90f-7d71-402c-8a66-dd1af5b83867","_cell_guid":"bf16bd44-3733-4294-8bf1-8031d6c7d800","trusted":true},"cell_type":"code","source":"#Separating churn and non churn customers for analysis\nchurn     = telecom[telecom[\"Churn\"] == \"Yes\"]\nnot_churn = telecom[telecom[\"Churn\"] == \"No\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ec1de0c-30c7-4de3-8e82-e14476e5989f","_cell_guid":"c4455918-e5d8-4283-bf8a-b85f263713c0","trusted":true},"cell_type":"code","source":"#Write a function to configure pie chart\n\ndef plot_pie(column) :\n    \n    trace1 = go.Pie(values  = churn[column].value_counts().values.tolist(),\n                    labels  = churn[column].value_counts().keys().tolist(),\n                    hoverinfo = \"label+percent+name\",\n                    domain  = dict(x = [0,.48]),\n                    name    = \"Churn Customers\",\n                    marker  = dict(line = dict(width = 2,\n                                               color = \"rgb(243,243,243)\")\n                                        ),\n                    hole    = .6\n                   )\n    \n    trace2 = go.Pie(values  = not_churn[column].value_counts().values.tolist(),\n                    labels  = not_churn[column].value_counts().keys().tolist(),\n                    hoverinfo = \"label+percent+name\",\n                    marker  = dict(line = dict(width = 2,\n                                               color = \"rgb(243,243,243)\")\n                                  ),\n                    domain  = dict(x = [.52,1]),\n                    hole    = .6,\n                    name    = \"Non churn Customers\" \n                   )\n    \n    layout = go.Layout(dict(title = column + \" distribution in customer attrition \",\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            annotations = [dict(text = \"Churn\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .22, y = .5),\n                                           dict(text = \"Non churn\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .80,y = .5\n                                            )\n                                          ]\n                           )\n                      )\n    data = [trace1,trace2]\n    fig  = go.Figure(data = data,layout = layout)\n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfe123eb-6e09-42be-a944-4d61e311ff9a","_cell_guid":"f4a10b7b-f0df-4aef-b658-f3c623933da4","trusted":true},"cell_type":"markdown","source":"# 3.2 Demographic Analysis\n\nLet's first understand the gender, age range, partnerand dependent status of the customers"},{"metadata":{"_uuid":"81e96fa3-4513-4cad-8463-96e3ea337fc9","_cell_guid":"0cd2cca6-75cb-46a8-aa0c-b73bd929979e","trusted":true},"cell_type":"markdown","source":"## 3.2.1 Gender\n\n- About half of the customers in our data set are male while the other half are female\n- Gender is not an indicative of churn."},{"metadata":{"_uuid":"72a59dfa-ff7b-4d6a-b813-9a3d304739aa","_cell_guid":"7e9ba06d-12ef-41d5-bcb0-a38619158209","trusted":true},"cell_type":"code","source":"plot_pie(\"gender\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34e03b1c-edf2-4b30-8a8d-7ce75283fcc7","_cell_guid":"fb9dd5f0-75d1-4e99-99f1-3ea5c41b2015","trusted":true},"cell_type":"markdown","source":"## 3.2.2 Senior Citizen"},{"metadata":{"_uuid":"c61df7d1-95c0-427a-9d3b-27e9d75272c4","_cell_guid":"49439b39-0ee1-4b4b-93cc-688c6365d9a3","trusted":true},"cell_type":"markdown","source":" - There are only 16% of the customers who are senior citizens. Thus most of our customers in the data are younger people.\n - Senior Citizen has a higher churn rate:  25.5% Churn customers are Senior Citizen, as compared to 12.9% of Non-churn customers are Senior Citizen"},{"metadata":{"_uuid":"c651a2bf-9e91-4926-aa82-33e36d1fc98c","_cell_guid":"b5014417-14b2-4f5a-959f-46fffc08e107","trusted":true},"cell_type":"code","source":"ax = (telecom['SeniorCitizen'].value_counts()*100.0 /len(telecom))\\\n.plot.pie(autopct='%.1f%%', labels = ['No', 'Yes'],figsize =(5,5), fontsize = 12 )                                                                           \nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.set_ylabel('Senior Citizens',fontsize = 12)\nax.set_title('% of Senior Citizens', fontsize = 12)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2d7ea38-3d6f-45b3-b1dd-76010d7f0536","_cell_guid":"b9e55b82-abcb-4783-b8dd-977959184436","trusted":true},"cell_type":"code","source":"plot_pie(\"SeniorCitizen\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"035f59b1-1153-46ed-ac33-fefad584bca1","_cell_guid":"1eef3603-2f2d-43bf-96f6-33f1614aad3f","trusted":true},"cell_type":"markdown","source":"## 3.2.3 Partner and Dependent Status"},{"metadata":{"_uuid":"a1604eef-440e-41e4-b78a-b8ebc35d8f7f","_cell_guid":"61ba04fb-24e9-430c-ae44-6ecb7c8f6f80","trusted":true},"cell_type":"markdown","source":" - About half of the customers have a partner, while only 30% of the total customers have dependents. \n - Customers without partners are more likely to churn.\n - Customers without dependents are more likely to churn."},{"metadata":{"_uuid":"55ad26a9-b662-4203-a140-ede4ff49ae01","_cell_guid":"2b023d47-1b4f-442b-bac0-cef1af6cb018","trusted":true},"cell_type":"code","source":"ax = (telecom['Partner'].value_counts()*100.0 /len(telecom))\\\n.plot.pie(autopct='%.1f%%', labels = ['No', 'Yes'],figsize =(5,5), fontsize = 12 )                                                                           \nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.set_ylabel('Partner',fontsize = 12)\nax.set_title('% of Partner', fontsize = 12)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f91e39b4-a9b2-46f4-8f29-2e195f571637","_cell_guid":"29f65c61-1872-4a8a-b7d1-a781c51d1ad1","trusted":true},"cell_type":"code","source":"ax= (telecom['Dependents'].value_counts()*100.0 /len(telecom))\\\n.plot.pie(autopct='%.1f%%', labels = ['No', 'Yes'],figsize =(5,5), fontsize = 12 )   \nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.set_ylabel('Dependents',fontsize = 12)\nax.set_title('% of Dependents', fontsize = 12)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f2bdaf6-05e4-48cc-b798-ae1df70f50a1","_cell_guid":"bb5cd704-116b-4f0f-98c9-b88b131520f9","trusted":true},"cell_type":"code","source":"plot_pie(\"Partner\")\nplot_pie(\"Dependents\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7dc13fbc-b688-447d-b19f-3634f26f120f","_cell_guid":"5547a03d-6c4e-466e-81d6-018ba8a83119","trusted":true},"cell_type":"markdown","source":"# 3.3 Customer Account Information"},{"metadata":{"_uuid":"ec6cfba4-48d5-4026-93c4-9ab6da8270e9","_cell_guid":"e8c5714b-0cc6-4ba7-ba48-60c0f9d2efb5","trusted":true},"cell_type":"markdown","source":"# 3.3.1 Tenure\n\n- Recent customers are more likely to churn\n- For non-churn customers, they tend to stay longer with the telecom company."},{"metadata":{"_uuid":"dbd2d6eb-efb7-4844-afaf-bff839c7427f","_cell_guid":"ab32b0f5-b737-4ce0-85e4-b6ba2679c918","trusted":true},"cell_type":"code","source":"def kdeplot(feature):\n    plt.figure(figsize=(9, 4))\n    plt.title(\"KDE for {}\".format(feature))\n    ax0 = sns.kdeplot(telecom[telecom['Churn'] == 'No'][feature].dropna(), color= 'navy', label= 'Churn: No')\n    ax1 = sns.kdeplot(telecom[telecom['Churn'] == 'Yes'][feature].dropna(), color= 'orange', label= 'Churn: Yes')\n\nkdeplot('tenure')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f65937b-0207-47c8-bfc9-b45999479b80","_cell_guid":"34d4c336-5582-442c-b856-22f6ffc3ac5f","trusted":true},"cell_type":"markdown","source":"# 3.3.2 Contract Type\n\n- 55% Month-to-month, 24% Two-year, 21% One-year\n- Among churn customers, 89% are from month-to-month."},{"metadata":{"_uuid":"90262de1-4dc0-45e2-a6d8-522be9e49711","_cell_guid":"59eab1af-3cf7-436b-819a-78cd87f810ea","trusted":true},"cell_type":"code","source":"ax = (telecom['Contract'].value_counts()*100.0 /len(telecom))\\\n.plot.pie(autopct='%.1f%%',figsize =(5,5), fontsize = 12 )                                                                           \nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.set_ylabel('Contract',fontsize = 12)\nax.set_title('% of Contract', fontsize = 12)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"40a71dde-610c-48b3-abeb-1536c4f28446","_cell_guid":"5f4fdb80-a72c-4def-b3a0-5d370b9247f6","trusted":true},"cell_type":"code","source":"plot_pie(\"Contract\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d9990fa-c9c5-4c1a-b369-5d0dba00b9a6","_cell_guid":"83413792-4c73-4630-a70d-037c6f7d5aab","trusted":true},"cell_type":"markdown","source":"# 3.4 Services"},{"metadata":{"_uuid":"4ca5618d-c84b-439f-9f5d-411c88a0c394","_cell_guid":"0593b21c-da1f-4d96-9e8b-49436f8a2a00","trusted":true},"cell_type":"code","source":"services = ['PhoneService','MultipleLines','InternetService','OnlineSecurity',\n           'OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\n\nfig, axes = plt.subplots(nrows = 3,ncols = 3,figsize = (15,12))\nfor i, item in enumerate(services):\n    if i < 3:\n        ax = telecom[item].value_counts().plot(kind = 'bar',ax=axes[i,0],rot = 0)\n        \n    elif i >=3 and i < 6:\n        ax = telecom[item].value_counts().plot(kind = 'bar',ax=axes[i-3,1],rot = 0)\n        \n    elif i < 9:\n        ax = telecom[item].value_counts().plot(kind = 'bar',ax=axes[i-6,2],rot = 0)\n    ax.set_title(item)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ba121fc-e577-44a4-9ae9-9e17ba70c6c8","_cell_guid":"f1545de8-8590-4479-9d1f-98b146357151","trusted":true},"cell_type":"markdown","source":"# 3.5 Monthly and Total Charges"},{"metadata":{"_uuid":"0e294343-efca-40da-a226-90c247810db2","_cell_guid":"b4c487e7-3aae-4a7f-a3f2-f69cd10e1d73","trusted":true},"cell_type":"markdown","source":"- We observe that the total charges increases as the monthly bill for a customer increases.\n- Higher % of cusotmers churn when the monthly charges are high.\n- Higher churn when the total charges are lower."},{"metadata":{"_uuid":"71039b5d-3898-4566-abab-ba650df63be8","_cell_guid":"57c92786-b012-4414-a314-a08d7353aca3","trusted":true},"cell_type":"code","source":"telecom[['MonthlyCharges', 'TotalCharges']].plot.scatter(x = 'MonthlyCharges',\n                                                              y='TotalCharges')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"596610dd-1bcf-4f28-becd-4573e74f7299","_cell_guid":"5ccaee2d-0e2d-4f45-a176-36ab03614d3d","trusted":true},"cell_type":"code","source":"kdeplot(\"MonthlyCharges\")\nkdeplot(\"TotalCharges\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"828c7228-d63e-4663-b424-6d502083ad9b","_cell_guid":"be449d52-da61-4f5d-95d8-22d7c82aa001","trusted":true},"cell_type":"markdown","source":"# 4. Model Building\n\nWe will develop Logistic Regression, Random Forest, and XG Boost during this workshop"},{"metadata":{"_uuid":"c6d046d7-049d-4aa5-832a-d4060cb21a1e","_cell_guid":"d7c8cab8-0fb7-465f-b942-1fd0dc1731cc","trusted":true},"cell_type":"markdown","source":"# 4.1 Data Preprocessing"},{"metadata":{"_uuid":"f0883f14-76a8-46dc-a7fb-11a49a84b4ca","_cell_guid":"51f5d010-1263-42a4-b355-e0d02bf3270d","trusted":true},"cell_type":"markdown","source":"# 4.1.1 Convert Categorical Variables to dummy variables"},{"metadata":{"_uuid":"2397b059-33bc-4d9a-b626-31905a7800a2","_cell_guid":"cf1ba2b3-1055-4d05-9deb-6dfd875d83f5","trusted":true},"cell_type":"markdown","source":"Many machine learning algorithms can support categorical values without further manipulation but there are many more algorithms that do not. Therefore we need to turn these categorical variables(text attributes) into numerical values for further processing.\n\nA common apporach is called one hot encoding, which is to convert each category value into a new column and assigns a 1 or 0 (True/False) value to the column. This has the benefit of not weighting a value improperly but does have the downside of adding more columns to the dataset.\n\nPandas supports this feature using get_dummies."},{"metadata":{"_uuid":"188b9d0b-0d35-4cdf-8b44-3f62a9f0be19","_cell_guid":"d738d45a-6129-47c1-9889-795f364f20bd","trusted":true},"cell_type":"code","source":"#Convertin the predictor variable in a binary numeric variable\ntelecom['Churn'].replace(to_replace='Yes', value=1, inplace=True)\ntelecom['Churn'].replace(to_replace='No',  value=0, inplace=True)\n\nId_col = ['customerID']\ntarget_col = ['Churn']\n\n#Let's convert all the categorical variables into dummy variables\ncat_cols = telecom.nunique()[telecom.nunique()<5].keys().tolist()\ncat_cols = [x for x in cat_cols if x not in target_col + Id_col]\nnum_cols = [x for x in telecom.columns if x not in cat_cols + target_col + Id_col]\ntelecom2 = pd.get_dummies(data=telecom, columns = cat_cols)\ntelecom2.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f274d54d-1df7-43f0-ab9e-3118125eae24","_cell_guid":"d1fe1b7e-ddec-4651-81cd-2188409e8667","trusted":true},"cell_type":"markdown","source":"# 4.1.2 Scaling all variables"},{"metadata":{"_uuid":"0bc1cedf-ce58-49d2-bfcc-682b6fbba9e0","_cell_guid":"b1b2ce82-02bf-4a3b-a678-a7e45a308786","trusted":true},"cell_type":"code","source":"# We will use the data frame where we had created dummy variables\ny = telecom2['Churn'].values\nX = telecom2.drop(columns = ['customerID','Churn'])\n\n# Scaling all the variables to a range of 0 to 1\nfrom sklearn.preprocessing import MinMaxScaler\nfeatures = X.columns.values\nscaler = MinMaxScaler(feature_range = (0,1))\nscaler.fit(X)\nX = pd.DataFrame(scaler.transform(X))\nX.columns = features","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30fdf57c-f7d4-4b8e-bc4a-21b4da245fda","_cell_guid":"a851bc6e-90a6-4469-942c-940623d12ac4","trusted":true},"cell_type":"markdown","source":"# 4.1.3 Correlation Analysis"},{"metadata":{"_uuid":"9e59e28e-86f0-45ae-90e1-482cca99f0df","_cell_guid":"3587af70-0e4d-43d4-b94c-22eedadf8934","trusted":true},"cell_type":"code","source":"#Get Correlation of \"Churn\" with other variables:\nplt.figure(figsize=(15,8))\ntelecom2.corr()['Churn'].sort_values(ascending = False).plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"165e9ff3-e2bc-40fa-9c18-1efdb304055e","_cell_guid":"3c70ae07-6599-4900-a1f8-ab43205e4da3","trusted":true},"cell_type":"markdown","source":"Month to month contracts, absence of online security and tech support seem to be positively correlated with churn. While, tenure, two year contracts seem to be negatively correlated with churn. \n\nInterestingly, services such as Online security, streaming TV, online backup, tech support, etc. without internet connection seem to be negatively related to churn.\n\nWe will explore the patterns for the above correlations below before we delve into modelling and identifying the important variables."},{"metadata":{"_uuid":"1dfaf9ea-eef8-42fb-8b02-55ae9d0a2246","_cell_guid":"a8b9cf32-4a54-4ce8-8f10-47ae9fc6f847","trusted":true},"cell_type":"markdown","source":"# 4.2 Baseline Model - Logistic Regression"},{"metadata":{},"cell_type":"markdown","source":"The goal in ML is to build a model that generalizes well to the new data. Therefore the dataset is split into the Training dataset and Testing dataset. \n\nTesting dataset serves as a proxy for new data to evaluate a trained ML model and determine if the model has over-fitted the data. \n\nTherefore we split the dataset by using 70% for training, and remaining 30% for testing."},{"metadata":{"_uuid":"90a2df00-3605-4829-8246-951604a04b9c","_cell_guid":"8097e485-a4c9-4834-9f3a-e54386fdc5f0","trusted":true},"cell_type":"code","source":"# Create Train & Test Data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting customer churn is a binary classification (Churn vs Non-churn) problem, therefore Logistic Regression will be used to serve as a baseline model.\n\nLogistic Regression is characterized by a logisitic function, also called the sigmoid function, to model a categorical dependent variable based on one or more independent variables. "},{"metadata":{},"cell_type":"markdown","source":"Performance Matrics to evaluate ML Models.\n\n- Accuracy Score - ratio of number of correct predictions to the total number of input samples. It works well only if te dataset is balanced (equal number of samples belonging to each class) If the dataset is imbalanced, it may give us a false sense of achieving high accuracy (the model starts to cheat itself)\n\n- Precision: It is the number of correct positive results divided by the number of positive results predicted by the classifier. \n  Precision = TP / (TP+FP) it attempts to answer what proportion of positive identifications was actually correct?\n \n- Recall: It is the number of correct positive results divided by the number of all samples that should have been identified as positive\n  Recall = TP / (TP + FN) it attempts to answer what proportion of actual positives was identified correctly?\n  \n- Area Under ROCurve: ROC (Receiver Operating Characteristics) Curve is a plot of the proportion of true positives vs. the proportion of false positives at different probability cutoffs, AUC represents degree of separability. It tells how much the model is capable of distinguishing between classes. Higher the AUC, better the model is predicting 0s as 0s and 1s as 1s. \n\n- Feature Importance measures the predicting power of input features based on how useful they are at predicting a target variables. "},{"metadata":{"_uuid":"08ef88d9-00c9-45d1-8ebe-0e6173e74b6f","_cell_guid":"dc97d61b-7827-4ff5-85c4-b3e4d7c55061","trusted":true},"cell_type":"code","source":"# Running logistic regression model\nLogReg_Model = LogisticRegression()\nLogReg_Result = LogReg_Model.fit(X_train, y_train)\n#Prediction\nLogReg_Prediction = LogReg_Model.predict(X_test)\nLogReg_Probabilities = LogReg_Model.predict_proba(X_test)\n\nprint(\"Logistic Regression\")\nprint(\"\\n Classification Report: \\n\", classification_report(y_test,LogReg_Prediction))\nprint(\"Accuracy Score: \",accuracy_score(y_test,LogReg_Prediction))\n\n#roc AUC\nLogReg_AUC = roc_auc_score(y_test, LogReg_Prediction)\nprint(\"Area under curve : \", LogReg_AUC, \"\\n\")\nfpr,tpr,threasholds = roc_curve(y_test,LogReg_Probabilities[:,1])\n\n#Feature Importance\nCoef = pd.Series(LogReg_Model.coef_[0],\n                 index=X.columns.values)\n\nprint(\"Feature Importance by Coefficients : \\n\",Coef.sort_values(ascending = True))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e875a2c0-a624-4121-b6c4-2cfd40797f4b","_cell_guid":"973b127d-3663-46ea-a5dd-01ab0ecb7351","trusted":true},"cell_type":"markdown","source":"**Observations**\n\nWe can see that some variables have a negative relation to our predicted variable (Churn), while some have positive relation. Negative relation means that likeliness of churn decreases with that variable. Let us summarize some of the interesting features below:\n* As we saw in our EDA, having a 2-year contract reduces chances of churn. 2-year contract along with tenure have the most negative relation with Churn as predicted by logistic regressions\n* Total charges, monthly contracts, fibre optic internet services and seniority can lead to higher churn rates."},{"metadata":{"_uuid":"53999710-8345-41a5-87ca-0fd765dcd4e1","_cell_guid":"a6311107-a4e8-4e84-8191-89f4bebede19","trusted":true},"cell_type":"markdown","source":"# 4.3 Random Forest"},{"metadata":{},"cell_type":"markdown","source":"Random forests are an ensemble learning method for classifiction. Random Forests grows many classification decision trees. To classify a new object from an input vector, put the input vector down each of the trees in the forest. Each tree gives a classification, and we say the tree \"votes\" for that class. The forest chooses the classification having the most votes."},{"metadata":{"_uuid":"14704ea1-d988-423c-80f9-e4ea5447eb53","_cell_guid":"5e8767de-45ef-4b45-a174-fef0746f8a2c","trusted":true},"cell_type":"code","source":"RF_Model = RandomForestClassifier(n_estimators=500)\nRF_Model.fit(X_train, y_train)\n\nRF_Result = RF_Model.fit(X_train, y_train)\nRF_Prediction = RF_Model.predict(X_test)\nRF_Probabilities = RF_Model.predict_proba(X_test)\n\nprint(\"Random Forest\")\nprint(\"\\n Classification Report: \\n\", classification_report(y_test,RF_Prediction))\nprint(\"Accuracy Score: \",accuracy_score(y_test,RF_Prediction))\n\n#roc AUC\nRF_AUC = roc_auc_score(y_test, RF_Prediction)\nprint(\"Area under curve : \", RF_AUC, \"\\n\")\nfpr,tpr,threasholds = roc_curve(y_test,RF_Probabilities[:,1])\n\n#Feature Importance\nfeature_importance=RF_Model.feature_importances_\nCoef = pd.Series(feature_importance,\n                 index=X.columns.values)\n\nprint(\"Feature Importance : \\n\",Coef.sort_values(ascending = False))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"340ed319-483a-4545-85e4-1e4d71af614f","_cell_guid":"929b9853-6499-44dc-9d6e-467f2cc671c4","trusted":true},"cell_type":"markdown","source":"**Observations:**\n\n* From random forest algorithm, total charges, tenure and monthly contract, monthly charges, monthly contracts are the most important predictor variables to predict churn.\n* The results from random forest are very similar to that of the logistic regression and in line to what we had expected from our EDA"},{"metadata":{"_uuid":"333720b2-a964-41d6-8b7d-04631347aa4a","_cell_guid":"feb6b546-16e2-4119-9fc4-09b4e8a791bb","trusted":true},"cell_type":"markdown","source":"# 4.4 XGBoost"},{"metadata":{},"cell_type":"markdown","source":"XGBoost is an implementation of gradient boosting decision trees designed for speed and perormance. It is effective for a wide range of regression and classification problems.\n\n\nGradient boosting is an approach where new models are created that predict the residuals or errors of prior models, Models are added sequentially until no further improvements can be ade. And then added together to make the final prediction. It is calld gradient boosting because it uses a gradient descent algorithm to minimize the loss when adding new models. \n\nXGBoost works well with imbalanced dataset as it offers a way to tune the training algorithm to pay more attention to misclassification of the minority class for datasets with a skewed class distribution. \n\nHyperparamter Tuning: scale_pos_weight (positive class refers to the minority class Y=1), by default it will be set to 1\n\n"},{"metadata":{"_uuid":"92d13d81-05c5-496a-ad01-0d4c4332b4ef","_cell_guid":"1678d27c-2d04-4047-a575-85713d5ce88f","trusted":true},"cell_type":"code","source":"XGBoost_Model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                    colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n                    max_depth = 3, min_child_weight=1, missing=None, n_estimators=100,\n                    n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n                    reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n                    subsample=1)\n\nXGBoost_Model.fit(X_train, y_train)\n\nXGBoost_Result = XGBoost_Model.fit(X_train, y_train)\nXGBoost_Prediction = XGBoost_Model.predict(X_test)\nXGBoost_Probabilities = XGBoost_Model.predict_proba(X_test)\n\nprint(\"XGBoost\")\nprint(\"\\n Classification Report: \\n\", classification_report(y_test,XGBoost_Prediction))\nprint(\"Accuracy Score: \",accuracy_score(y_test,XGBoost_Prediction))\n\n#roc AUC\nXGBoost_AUC = roc_auc_score(y_test, XGBoost_Prediction)\nprint(\"Area under curve : \", XGBoost_AUC, \"\\n\")\nfpr,tpr,threasholds = roc_curve(y_test,XGBoost_Probabilities[:,1])\n\n#Feature Importance\nfeature_importance=XGBoost_Model.feature_importances_\nCoef = pd.Series(feature_importance,\n                 index=X.columns.values)\n\nprint(\"Feature Importance : \\n\",Coef.sort_values(ascending = False))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}